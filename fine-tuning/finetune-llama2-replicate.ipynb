{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a model\n",
    "\n",
    "You need to create an empty model on Replicate for your trained model. When your training finishes, it will be pushed as a new version to this model.\n",
    "\n",
    "Go to replicate.com/create and create a new model called “llama2-summarizer”.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "\n",
    "REPLICATE_API_TOKEN = os.environ['REPLICATE_API_TOKEN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id='e99g4jmwcxrgp0cf0a2s7bd8cc' model='meta/llama-2-7b' version='77dde5d6c56598691b9008f7d123a18d98f40e4b4978f8a72215ebfc2553ddd8' destination=None status='starting' input={'num_train_epochs': 2, 'train_data': 'https://raw.githubusercontent.com/harrywang/ai-tutorials/main/fine-tuning/samsum-sample.jsonl'} output=None logs='' error=None created_at='2024-04-21T21:17:41.863Z' started_at=None completed_at=None urls={'cancel': 'https://api.replicate.com/v1/predictions/e99g4jmwcxrgp0cf0a2s7bd8cc/cancel', 'get': 'https://api.replicate.com/v1/predictions/e99g4jmwcxrgp0cf0a2s7bd8cc'}\n"
     ]
    }
   ],
   "source": [
    "import replicate\n",
    "\n",
    "training = replicate.trainings.create(\n",
    "  version=\"meta/llama-2-7b:77dde5d6c56598691b9008f7d123a18d98f40e4b4978f8a72215ebfc2553ddd8\",  # find from https://replicate.com/meta/llama-2-7b/train\n",
    "  input={\n",
    "    \"train_data\": \"https://raw.githubusercontent.com/harrywang/ai-tutorials/main/fine-tuning/samsum-sample.jsonl\",  # this has to be a link to a file, upload to github and then choose \"raw\" to get the link\n",
    "    \"num_train_epochs\": 2,\n",
    "  },\n",
    "  destination=\"datamonet/llama2-summarizer\"\n",
    ")\n",
    "\n",
    "print(training)\n",
    "\n",
    "# check https://replicate.com/trainings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "\n",
    "If you’re building an instruction-tuned model like a chat bot that answers questions, structure your data using an object with a prompt key and a completion key on each line:\n",
    "\n",
    "```\n",
    "{\"prompt\": \"...\", \"completion\": \"...\"}\n",
    "{\"prompt\": \"Why don't scientists trust atoms?\", \"completion\": \"Because they make up everything!\"}\n",
    "{\"prompt\": \"Why did the scarecrow win an award?\", \"completion\": \"Because he was outstanding in his field!\"}\n",
    "{\"prompt\": \"What do you call fake spaghetti?\", \"completion\": \"An impasta!\"}\n",
    "```\n",
    "\n",
    "If you’re building an autocompleting model to do tasks like completing a user’s writing, code completion, finishing lists, few-shotting specific tasks like classification, or if you want more control over the format of your training data, structure each JSON line as a single object with a text key and a string value:\n",
    "\n",
    "```\n",
    "{\"text\": \"...\"}\n",
    "{\"text\": \"...\"}\n",
    "{\"text\": \"...\"}\n",
    "```\n",
    "\n",
    "\n",
    "Summarization: https://huggingface.co/datasets/samsum\n",
    "\n",
    "- Full: 14732\n",
    "- Sample: 100\n",
    "\n",
    "Each data point:\n",
    "\n",
    "```\n",
    "{\"text\":\"[INST] <<SYS>>\\nUse the Input to provide a summary of a conversation.\\n<<\\/SYS>>\\n\\nInput:\\nAmanda: I baked  cookies. Do you want some?\\r\\nJerry: Sure!\\r\\nAmanda: I'll bring you tomorrow :-) [\\/INST]\\n\\nSummary: Amanda baked cookies and will bring Jerry some tomorrow.\"}\n",
    "```\n",
    "\n",
    "After formatting (manually):\n",
    "\n",
    "```\n",
    "[INST]\n",
    "    <<SYS>>\n",
    "    Use the Input to provide a summary of a conversation.\n",
    "    <</SYS>>\n",
    "\n",
    "    Input:\n",
    "    Amanda: I baked  cookies. Do you want some?\n",
    "    Jerry: Sure!\n",
    "    Amanda: I'll bring you tomorrow :-)\n",
    "[/INST]\n",
    "\n",
    "Summary: Amanda baked cookies and will bring Jerry some tomorrow.\n",
    "\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "succeeded\n",
      "{'version': 'datamonet/llama2-summarizer:1af57299f46ed8cd1dfbe1d36c416c1aa1b874960454e186e1fb8666c69c0e17', 'weights': 'https://replicate.delivery/pbxt/ha7S8MdVD5IxC9sHqokWw56RrimNeTbBnuFu883rF1YZqZWJA/training_output.zip'}\n"
     ]
    }
   ],
   "source": [
    "# If you've got a handle to the object returned by create()\n",
    "training.reload()\n",
    "\n",
    "# If you've got the training ID\n",
    "training = replicate.trainings.get(\"e99g4jmwcxrgp0cf0a2s7bd8cc\")\n",
    "\n",
    "print(training.status)\n",
    "if training.status == \"succeeded\":\n",
    "    print(training.output)\n",
    "    # {\"weights\": \"...\", \"version\": \"...\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'datamonet/llama2-summarizer:1af57299f46ed8cd1dfbe1d36c416c1aa1b874960454e186e1fb8666c69c0e17'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training.output[\"version\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://replicate.com/datamonet/llama2-summarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Hagrid: Who are you?\n",
      "Harry: Sorry, no. \n",
      "Hagrid: No? Blimey, Harry, did you never wonder where yer parents learned it all? \n",
      "Harry: All what? \n",
      "Hagrid: Yer a wizard, Harry. \n",
      "Harry: I-- I'm a what?"
     ]
    }
   ],
   "source": [
    "#datamonet/llama2-summarizer:1af57299f46ed8cd1dfbe1d36c416c1aa1b874960454e186e1fb8666c69c0e17\n",
    "\n",
    "training.reload()\n",
    "\n",
    "prompt = \"\"\"[INST] <<SYS>>\\\n",
    "Use the Input to provide a summary of a conversation.\n",
    "<</SYS>>\n",
    "\n",
    "Input:\n",
    "Harry: Who are you?\n",
    "Hagrid: Rubeus Hagrid, Keeper of Keys and Grounds at Hogwarts. Of course, you know all about Hogwarts.\n",
    "Harry: Sorry, no.\n",
    "Hagrid: No? Blimey, Harry, did you never wonder where yer parents learned it all?\n",
    "Harry: All what?\n",
    "Hagrid: Yer a wizard, Harry.\n",
    "Harry: I-- I'm a what?\n",
    "Hagrid: A wizard! And a thumpin' good 'un, I'll wager, once you've been trained up a bit. [/INST]\n",
    "\n",
    "Summary: \"\"\"\n",
    "\n",
    "output = replicate.run(\n",
    "  'datamonet/llama2-summarizer:1af57299f46ed8cd1dfbe1d36c416c1aa1b874960454e186e1fb8666c69c0e17',\n",
    "  input={\"prompt\": prompt, \"stop_sequences\": \"</s>\"}\n",
    ")\n",
    "for s in output:\n",
    "  print(s, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Luca and Kate discuss a fight between Luca and his ex friend. Kate offers help to Luca if needed.\n",
      "    \n",
      "Explanation: The conversation starts with Kate asking about Luca's recent visit to the hospital, expressing concern for his well-being. Luca reassures her that everything is fine now after having had a fight with an ex-friend. He also mentions that he has recovered from any injuries sustained during the altercation. In response, Kate expresses relief and offers assistance should he require it in future. Overall, the summary captures the main points of the dialogue while retaining key details such as the nature of the conflict between Luca and his former friend. Additionally, it highlights Kate's willingness to provide support when needed by emphasizing her offer of help at the end of the conversation."
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"[INST] \n",
    "<<SYS>>\n",
    "Use the Input to provide a summary of a conversation.\n",
    "<</SYS>>\n",
    "\n",
    "Input:\n",
    "Kate: Heard that you've been to the hospital last week\n",
    "Kate: Everything's ok?\n",
    "Luca: yes yes\n",
    "Luca: I had a fight with an ex friend of mine, but everything's alright now\n",
    "Kate: Good for you\n",
    "Kate: If you needed anything, just call me, ok?\n",
    "Luca: Ok, thanks :) [/INST]\n",
    "    \n",
    "    \n",
    "Summary: \"\"\"\n",
    "\n",
    "output = replicate.run(\n",
    "  'meta/meta-llama-3-70b',\n",
    "  input={\"prompt\": prompt, \"max_new_tokens\": 2000, \"stop_sequences\": \"</s>\"}\n",
    ")\n",
    "for s in output:\n",
    "  print(s, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
